{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'c:\\\\Users\\\\Legion\\\\.conda\\\\envs\\\\tf26\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(Xtrain.shape[1], 1),\n",
    "                            torch.nn.Sigmoid()\n",
    "                        )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "Xtest = torch.tensor(Xtest, dtype=torch.float32)\n",
    "\n",
    "Ytrain = torch.tensor(Ytrain.reshape(-1,1), dtype=torch.float32)\n",
    "Ytest = torch.tensor(Ytest.reshape(-1,1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 184/1000 [00:00<00:00, 1839.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000,  Loss: 0.6555,  Accuracy: 0.653\n",
      "Epoch 1/1000,  Loss: 0.6493,  Accuracy: 0.666\n",
      "Epoch 2/1000,  Loss: 0.6433,  Accuracy: 0.681\n",
      "Epoch 3/1000,  Loss: 0.6372,  Accuracy: 0.695\n",
      "Epoch 4/1000,  Loss: 0.6313,  Accuracy: 0.701\n",
      "Epoch 5/1000,  Loss: 0.6254,  Accuracy: 0.714\n",
      "Epoch 6/1000,  Loss: 0.6196,  Accuracy: 0.723\n",
      "Epoch 7/1000,  Loss: 0.6139,  Accuracy: 0.73\n",
      "Epoch 8/1000,  Loss: 0.6082,  Accuracy: 0.738\n",
      "Epoch 9/1000,  Loss: 0.6026,  Accuracy: 0.743\n",
      "Epoch 10/1000,  Loss: 0.5971,  Accuracy: 0.743\n",
      "Epoch 11/1000,  Loss: 0.5916,  Accuracy: 0.747\n",
      "Epoch 12/1000,  Loss: 0.5863,  Accuracy: 0.752\n",
      "Epoch 13/1000,  Loss: 0.581,  Accuracy: 0.763\n",
      "Epoch 14/1000,  Loss: 0.5758,  Accuracy: 0.78\n",
      "Epoch 15/1000,  Loss: 0.5706,  Accuracy: 0.793\n",
      "Epoch 16/1000,  Loss: 0.5655,  Accuracy: 0.802\n",
      "Epoch 17/1000,  Loss: 0.5605,  Accuracy: 0.804\n",
      "Epoch 18/1000,  Loss: 0.5556,  Accuracy: 0.809\n",
      "Epoch 19/1000,  Loss: 0.5508,  Accuracy: 0.811\n",
      "Epoch 20/1000,  Loss: 0.546,  Accuracy: 0.813\n",
      "Epoch 21/1000,  Loss: 0.5413,  Accuracy: 0.826\n",
      "Epoch 22/1000,  Loss: 0.5367,  Accuracy: 0.826\n",
      "Epoch 23/1000,  Loss: 0.5321,  Accuracy: 0.826\n",
      "Epoch 24/1000,  Loss: 0.5276,  Accuracy: 0.831\n",
      "Epoch 25/1000,  Loss: 0.5232,  Accuracy: 0.831\n",
      "Epoch 26/1000,  Loss: 0.5189,  Accuracy: 0.835\n",
      "Epoch 27/1000,  Loss: 0.5146,  Accuracy: 0.837\n",
      "Epoch 28/1000,  Loss: 0.5104,  Accuracy: 0.842\n",
      "Epoch 29/1000,  Loss: 0.5063,  Accuracy: 0.844\n",
      "Epoch 30/1000,  Loss: 0.5022,  Accuracy: 0.844\n",
      "Epoch 31/1000,  Loss: 0.4982,  Accuracy: 0.846\n",
      "Epoch 32/1000,  Loss: 0.4943,  Accuracy: 0.853\n",
      "Epoch 33/1000,  Loss: 0.4904,  Accuracy: 0.859\n",
      "Epoch 34/1000,  Loss: 0.4866,  Accuracy: 0.859\n",
      "Epoch 35/1000,  Loss: 0.4829,  Accuracy: 0.859\n",
      "Epoch 36/1000,  Loss: 0.4792,  Accuracy: 0.859\n",
      "Epoch 37/1000,  Loss: 0.4756,  Accuracy: 0.859\n",
      "Epoch 38/1000,  Loss: 0.472,  Accuracy: 0.864\n",
      "Epoch 39/1000,  Loss: 0.4685,  Accuracy: 0.864\n",
      "Epoch 40/1000,  Loss: 0.4651,  Accuracy: 0.866\n",
      "Epoch 41/1000,  Loss: 0.4617,  Accuracy: 0.868\n",
      "Epoch 42/1000,  Loss: 0.4584,  Accuracy: 0.868\n",
      "Epoch 43/1000,  Loss: 0.4551,  Accuracy: 0.87\n",
      "Epoch 44/1000,  Loss: 0.4519,  Accuracy: 0.873\n",
      "Epoch 45/1000,  Loss: 0.4487,  Accuracy: 0.875\n",
      "Epoch 46/1000,  Loss: 0.4456,  Accuracy: 0.875\n",
      "Epoch 47/1000,  Loss: 0.4425,  Accuracy: 0.875\n",
      "Epoch 48/1000,  Loss: 0.4395,  Accuracy: 0.879\n",
      "Epoch 49/1000,  Loss: 0.4365,  Accuracy: 0.879\n",
      "Epoch 50/1000,  Loss: 0.4335,  Accuracy: 0.879\n",
      "Epoch 51/1000,  Loss: 0.4307,  Accuracy: 0.879\n",
      "Epoch 52/1000,  Loss: 0.4278,  Accuracy: 0.884\n",
      "Epoch 53/1000,  Loss: 0.425,  Accuracy: 0.884\n",
      "Epoch 54/1000,  Loss: 0.4223,  Accuracy: 0.888\n",
      "Epoch 55/1000,  Loss: 0.4196,  Accuracy: 0.888\n",
      "Epoch 56/1000,  Loss: 0.4169,  Accuracy: 0.888\n",
      "Epoch 57/1000,  Loss: 0.4143,  Accuracy: 0.888\n",
      "Epoch 58/1000,  Loss: 0.4117,  Accuracy: 0.89\n",
      "Epoch 59/1000,  Loss: 0.4091,  Accuracy: 0.89\n",
      "Epoch 60/1000,  Loss: 0.4066,  Accuracy: 0.89\n",
      "Epoch 61/1000,  Loss: 0.4041,  Accuracy: 0.89\n",
      "Epoch 62/1000,  Loss: 0.4017,  Accuracy: 0.892\n",
      "Epoch 63/1000,  Loss: 0.3992,  Accuracy: 0.892\n",
      "Epoch 64/1000,  Loss: 0.3969,  Accuracy: 0.892\n",
      "Epoch 65/1000,  Loss: 0.3945,  Accuracy: 0.892\n",
      "Epoch 66/1000,  Loss: 0.3922,  Accuracy: 0.892\n",
      "Epoch 67/1000,  Loss: 0.3899,  Accuracy: 0.892\n",
      "Epoch 68/1000,  Loss: 0.3877,  Accuracy: 0.892\n",
      "Epoch 69/1000,  Loss: 0.3855,  Accuracy: 0.895\n",
      "Epoch 70/1000,  Loss: 0.3833,  Accuracy: 0.895\n",
      "Epoch 71/1000,  Loss: 0.3811,  Accuracy: 0.895\n",
      "Epoch 72/1000,  Loss: 0.379,  Accuracy: 0.899\n",
      "Epoch 73/1000,  Loss: 0.3769,  Accuracy: 0.901\n",
      "Epoch 74/1000,  Loss: 0.3748,  Accuracy: 0.901\n",
      "Epoch 75/1000,  Loss: 0.3728,  Accuracy: 0.901\n",
      "Epoch 76/1000,  Loss: 0.3708,  Accuracy: 0.901\n",
      "Epoch 77/1000,  Loss: 0.3688,  Accuracy: 0.903\n",
      "Epoch 78/1000,  Loss: 0.3668,  Accuracy: 0.905\n",
      "Epoch 79/1000,  Loss: 0.3649,  Accuracy: 0.905\n",
      "Epoch 80/1000,  Loss: 0.363,  Accuracy: 0.908\n",
      "Epoch 81/1000,  Loss: 0.3611,  Accuracy: 0.908\n",
      "Epoch 82/1000,  Loss: 0.3592,  Accuracy: 0.905\n",
      "Epoch 83/1000,  Loss: 0.3574,  Accuracy: 0.908\n",
      "Epoch 84/1000,  Loss: 0.3555,  Accuracy: 0.908\n",
      "Epoch 85/1000,  Loss: 0.3537,  Accuracy: 0.908\n",
      "Epoch 86/1000,  Loss: 0.352,  Accuracy: 0.908\n",
      "Epoch 87/1000,  Loss: 0.3502,  Accuracy: 0.908\n",
      "Epoch 88/1000,  Loss: 0.3485,  Accuracy: 0.908\n",
      "Epoch 89/1000,  Loss: 0.3468,  Accuracy: 0.908\n",
      "Epoch 90/1000,  Loss: 0.3451,  Accuracy: 0.908\n",
      "Epoch 91/1000,  Loss: 0.3434,  Accuracy: 0.908\n",
      "Epoch 92/1000,  Loss: 0.3417,  Accuracy: 0.908\n",
      "Epoch 93/1000,  Loss: 0.3401,  Accuracy: 0.908\n",
      "Epoch 94/1000,  Loss: 0.3385,  Accuracy: 0.91\n",
      "Epoch 95/1000,  Loss: 0.3369,  Accuracy: 0.912\n",
      "Epoch 96/1000,  Loss: 0.3353,  Accuracy: 0.912\n",
      "Epoch 97/1000,  Loss: 0.3338,  Accuracy: 0.912\n",
      "Epoch 98/1000,  Loss: 0.3322,  Accuracy: 0.912\n",
      "Epoch 99/1000,  Loss: 0.3307,  Accuracy: 0.916\n",
      "Epoch 100/1000,  Loss: 0.3292,  Accuracy: 0.916\n",
      "Epoch 101/1000,  Loss: 0.3277,  Accuracy: 0.916\n",
      "Epoch 102/1000,  Loss: 0.3262,  Accuracy: 0.919\n",
      "Epoch 103/1000,  Loss: 0.3248,  Accuracy: 0.919\n",
      "Epoch 104/1000,  Loss: 0.3233,  Accuracy: 0.919\n",
      "Epoch 105/1000,  Loss: 0.3219,  Accuracy: 0.919\n",
      "Epoch 106/1000,  Loss: 0.3205,  Accuracy: 0.919\n",
      "Epoch 107/1000,  Loss: 0.3191,  Accuracy: 0.919\n",
      "Epoch 108/1000,  Loss: 0.3177,  Accuracy: 0.919\n",
      "Epoch 109/1000,  Loss: 0.3163,  Accuracy: 0.919\n",
      "Epoch 110/1000,  Loss: 0.315,  Accuracy: 0.919\n",
      "Epoch 111/1000,  Loss: 0.3136,  Accuracy: 0.919\n",
      "Epoch 112/1000,  Loss: 0.3123,  Accuracy: 0.919\n",
      "Epoch 113/1000,  Loss: 0.311,  Accuracy: 0.919\n",
      "Epoch 114/1000,  Loss: 0.3097,  Accuracy: 0.919\n",
      "Epoch 115/1000,  Loss: 0.3084,  Accuracy: 0.919\n",
      "Epoch 116/1000,  Loss: 0.3072,  Accuracy: 0.919\n",
      "Epoch 117/1000,  Loss: 0.3059,  Accuracy: 0.921\n",
      "Epoch 118/1000,  Loss: 0.3047,  Accuracy: 0.921\n",
      "Epoch 119/1000,  Loss: 0.3034,  Accuracy: 0.921\n",
      "Epoch 120/1000,  Loss: 0.3022,  Accuracy: 0.921\n",
      "Epoch 121/1000,  Loss: 0.301,  Accuracy: 0.923\n",
      "Epoch 122/1000,  Loss: 0.2998,  Accuracy: 0.925\n",
      "Epoch 123/1000,  Loss: 0.2986,  Accuracy: 0.925\n",
      "Epoch 124/1000,  Loss: 0.2974,  Accuracy: 0.925\n",
      "Epoch 125/1000,  Loss: 0.2963,  Accuracy: 0.925\n",
      "Epoch 126/1000,  Loss: 0.2951,  Accuracy: 0.925\n",
      "Epoch 127/1000,  Loss: 0.294,  Accuracy: 0.93\n",
      "Epoch 128/1000,  Loss: 0.2929,  Accuracy: 0.93\n",
      "Epoch 129/1000,  Loss: 0.2918,  Accuracy: 0.93\n",
      "Epoch 130/1000,  Loss: 0.2907,  Accuracy: 0.93\n",
      "Epoch 131/1000,  Loss: 0.2896,  Accuracy: 0.93\n",
      "Epoch 132/1000,  Loss: 0.2885,  Accuracy: 0.932\n",
      "Epoch 133/1000,  Loss: 0.2874,  Accuracy: 0.932\n",
      "Epoch 134/1000,  Loss: 0.2863,  Accuracy: 0.932\n",
      "Epoch 135/1000,  Loss: 0.2853,  Accuracy: 0.932\n",
      "Epoch 136/1000,  Loss: 0.2842,  Accuracy: 0.932\n",
      "Epoch 137/1000,  Loss: 0.2832,  Accuracy: 0.932\n",
      "Epoch 138/1000,  Loss: 0.2822,  Accuracy: 0.932\n",
      "Epoch 139/1000,  Loss: 0.2812,  Accuracy: 0.932\n",
      "Epoch 140/1000,  Loss: 0.2802,  Accuracy: 0.932\n",
      "Epoch 141/1000,  Loss: 0.2792,  Accuracy: 0.932\n",
      "Epoch 142/1000,  Loss: 0.2782,  Accuracy: 0.932\n",
      "Epoch 143/1000,  Loss: 0.2772,  Accuracy: 0.932\n",
      "Epoch 144/1000,  Loss: 0.2762,  Accuracy: 0.932\n",
      "Epoch 145/1000,  Loss: 0.2753,  Accuracy: 0.932\n",
      "Epoch 146/1000,  Loss: 0.2743,  Accuracy: 0.932\n",
      "Epoch 147/1000,  Loss: 0.2734,  Accuracy: 0.932\n",
      "Epoch 148/1000,  Loss: 0.2724,  Accuracy: 0.932\n",
      "Epoch 149/1000,  Loss: 0.2715,  Accuracy: 0.932\n",
      "Epoch 150/1000,  Loss: 0.2706,  Accuracy: 0.934\n",
      "Epoch 151/1000,  Loss: 0.2697,  Accuracy: 0.934\n",
      "Epoch 152/1000,  Loss: 0.2688,  Accuracy: 0.934\n",
      "Epoch 153/1000,  Loss: 0.2679,  Accuracy: 0.936\n",
      "Epoch 154/1000,  Loss: 0.267,  Accuracy: 0.936\n",
      "Epoch 155/1000,  Loss: 0.2661,  Accuracy: 0.936\n",
      "Epoch 156/1000,  Loss: 0.2652,  Accuracy: 0.938\n",
      "Epoch 157/1000,  Loss: 0.2643,  Accuracy: 0.938\n",
      "Epoch 158/1000,  Loss: 0.2635,  Accuracy: 0.938\n",
      "Epoch 159/1000,  Loss: 0.2626,  Accuracy: 0.941\n",
      "Epoch 160/1000,  Loss: 0.2618,  Accuracy: 0.941\n",
      "Epoch 161/1000,  Loss: 0.261,  Accuracy: 0.941\n",
      "Epoch 162/1000,  Loss: 0.2601,  Accuracy: 0.941\n",
      "Epoch 163/1000,  Loss: 0.2593,  Accuracy: 0.941\n",
      "Epoch 164/1000,  Loss: 0.2585,  Accuracy: 0.941\n",
      "Epoch 165/1000,  Loss: 0.2577,  Accuracy: 0.943\n",
      "Epoch 166/1000,  Loss: 0.2569,  Accuracy: 0.943\n",
      "Epoch 167/1000,  Loss: 0.2561,  Accuracy: 0.943\n",
      "Epoch 168/1000,  Loss: 0.2553,  Accuracy: 0.943\n",
      "Epoch 169/1000,  Loss: 0.2545,  Accuracy: 0.943\n",
      "Epoch 170/1000,  Loss: 0.2537,  Accuracy: 0.943\n",
      "Epoch 171/1000,  Loss: 0.2529,  Accuracy: 0.943\n",
      "Epoch 172/1000,  Loss: 0.2522,  Accuracy: 0.943\n",
      "Epoch 173/1000,  Loss: 0.2514,  Accuracy: 0.945\n",
      "Epoch 174/1000,  Loss: 0.2507,  Accuracy: 0.945\n",
      "Epoch 175/1000,  Loss: 0.2499,  Accuracy: 0.945\n",
      "Epoch 176/1000,  Loss: 0.2492,  Accuracy: 0.945\n",
      "Epoch 177/1000,  Loss: 0.2484,  Accuracy: 0.945\n",
      "Epoch 178/1000,  Loss: 0.2477,  Accuracy: 0.945\n",
      "Epoch 179/1000,  Loss: 0.247,  Accuracy: 0.945\n",
      "Epoch 180/1000,  Loss: 0.2462,  Accuracy: 0.945\n",
      "Epoch 181/1000,  Loss: 0.2455,  Accuracy: 0.945\n",
      "Epoch 182/1000,  Loss: 0.2448,  Accuracy: 0.945\n",
      "Epoch 183/1000,  Loss: 0.2441,  Accuracy: 0.945\n",
      "Epoch 184/1000,  Loss: 0.2434,  Accuracy: 0.943\n",
      "Epoch 185/1000,  Loss: 0.2427,  Accuracy: 0.943\n",
      "Epoch 186/1000,  Loss: 0.242,  Accuracy: 0.943\n",
      "Epoch 187/1000,  Loss: 0.2414,  Accuracy: 0.943\n",
      "Epoch 188/1000,  Loss: 0.2407,  Accuracy: 0.943\n",
      "Epoch 189/1000,  Loss: 0.24,  Accuracy: 0.943\n",
      "Epoch 190/1000,  Loss: 0.2393,  Accuracy: 0.943\n",
      "Epoch 191/1000,  Loss: 0.2387,  Accuracy: 0.943\n",
      "Epoch 192/1000,  Loss: 0.238,  Accuracy: 0.943\n",
      "Epoch 193/1000,  Loss: 0.2374,  Accuracy: 0.943\n",
      "Epoch 194/1000,  Loss: 0.2367,  Accuracy: 0.943\n",
      "Epoch 195/1000,  Loss: 0.2361,  Accuracy: 0.943\n",
      "Epoch 196/1000,  Loss: 0.2354,  Accuracy: 0.943\n",
      "Epoch 197/1000,  Loss: 0.2348,  Accuracy: 0.943\n",
      "Epoch 198/1000,  Loss: 0.2342,  Accuracy: 0.943\n",
      "Epoch 199/1000,  Loss: 0.2335,  Accuracy: 0.943\n",
      "Epoch 200/1000,  Loss: 0.2329,  Accuracy: 0.943\n",
      "Epoch 201/1000,  Loss: 0.2323,  Accuracy: 0.943\n",
      "Epoch 202/1000,  Loss: 0.2317,  Accuracy: 0.943\n",
      "Epoch 203/1000,  Loss: 0.2311,  Accuracy: 0.943\n",
      "Epoch 204/1000,  Loss: 0.2305,  Accuracy: 0.943\n",
      "Epoch 205/1000,  Loss: 0.2299,  Accuracy: 0.943\n",
      "Epoch 206/1000,  Loss: 0.2293,  Accuracy: 0.943\n",
      "Epoch 207/1000,  Loss: 0.2287,  Accuracy: 0.943\n",
      "Epoch 208/1000,  Loss: 0.2281,  Accuracy: 0.943\n",
      "Epoch 209/1000,  Loss: 0.2275,  Accuracy: 0.943\n",
      "Epoch 210/1000,  Loss: 0.2269,  Accuracy: 0.945\n",
      "Epoch 211/1000,  Loss: 0.2263,  Accuracy: 0.945\n",
      "Epoch 212/1000,  Loss: 0.2258,  Accuracy: 0.945\n",
      "Epoch 213/1000,  Loss: 0.2252,  Accuracy: 0.945\n",
      "Epoch 214/1000,  Loss: 0.2246,  Accuracy: 0.945\n",
      "Epoch 215/1000,  Loss: 0.2241,  Accuracy: 0.945\n",
      "Epoch 216/1000,  Loss: 0.2235,  Accuracy: 0.947\n",
      "Epoch 217/1000,  Loss: 0.223,  Accuracy: 0.947\n",
      "Epoch 218/1000,  Loss: 0.2224,  Accuracy: 0.947\n",
      "Epoch 219/1000,  Loss: 0.2219,  Accuracy: 0.947\n",
      "Epoch 220/1000,  Loss: 0.2213,  Accuracy: 0.947\n",
      "Epoch 221/1000,  Loss: 0.2208,  Accuracy: 0.947\n",
      "Epoch 222/1000,  Loss: 0.2203,  Accuracy: 0.947\n",
      "Epoch 223/1000,  Loss: 0.2197,  Accuracy: 0.947\n",
      "Epoch 224/1000,  Loss: 0.2192,  Accuracy: 0.947\n",
      "Epoch 225/1000,  Loss: 0.2187,  Accuracy: 0.947\n",
      "Epoch 226/1000,  Loss: 0.2182,  Accuracy: 0.947\n",
      "Epoch 227/1000,  Loss: 0.2176,  Accuracy: 0.947\n",
      "Epoch 228/1000,  Loss: 0.2171,  Accuracy: 0.947\n",
      "Epoch 229/1000,  Loss: 0.2166,  Accuracy: 0.947\n",
      "Epoch 230/1000,  Loss: 0.2161,  Accuracy: 0.947\n",
      "Epoch 231/1000,  Loss: 0.2156,  Accuracy: 0.947\n",
      "Epoch 232/1000,  Loss: 0.2151,  Accuracy: 0.947\n",
      "Epoch 233/1000,  Loss: 0.2146,  Accuracy: 0.947\n",
      "Epoch 234/1000,  Loss: 0.2141,  Accuracy: 0.947\n",
      "Epoch 235/1000,  Loss: 0.2136,  Accuracy: 0.947\n",
      "Epoch 236/1000,  Loss: 0.2131,  Accuracy: 0.947\n",
      "Epoch 237/1000,  Loss: 0.2126,  Accuracy: 0.947\n",
      "Epoch 238/1000,  Loss: 0.2121,  Accuracy: 0.947\n",
      "Epoch 239/1000,  Loss: 0.2117,  Accuracy: 0.947\n",
      "Epoch 240/1000,  Loss: 0.2112,  Accuracy: 0.947\n",
      "Epoch 241/1000,  Loss: 0.2107,  Accuracy: 0.949\n",
      "Epoch 242/1000,  Loss: 0.2102,  Accuracy: 0.949\n",
      "Epoch 243/1000,  Loss: 0.2098,  Accuracy: 0.949\n",
      "Epoch 244/1000,  Loss: 0.2093,  Accuracy: 0.949\n",
      "Epoch 245/1000,  Loss: 0.2088,  Accuracy: 0.949\n",
      "Epoch 246/1000,  Loss: 0.2084,  Accuracy: 0.949\n",
      "Epoch 247/1000,  Loss: 0.2079,  Accuracy: 0.949\n",
      "Epoch 248/1000,  Loss: 0.2075,  Accuracy: 0.949\n",
      "Epoch 249/1000,  Loss: 0.207,  Accuracy: 0.949\n",
      "Epoch 250/1000,  Loss: 0.2066,  Accuracy: 0.949\n",
      "Epoch 251/1000,  Loss: 0.2061,  Accuracy: 0.949\n",
      "Epoch 252/1000,  Loss: 0.2057,  Accuracy: 0.949\n",
      "Epoch 253/1000,  Loss: 0.2052,  Accuracy: 0.949\n",
      "Epoch 254/1000,  Loss: 0.2048,  Accuracy: 0.949\n",
      "Epoch 255/1000,  Loss: 0.2044,  Accuracy: 0.949\n",
      "Epoch 256/1000,  Loss: 0.2039,  Accuracy: 0.949\n",
      "Epoch 257/1000,  Loss: 0.2035,  Accuracy: 0.949\n",
      "Epoch 258/1000,  Loss: 0.2031,  Accuracy: 0.949\n",
      "Epoch 259/1000,  Loss: 0.2026,  Accuracy: 0.952\n",
      "Epoch 260/1000,  Loss: 0.2022,  Accuracy: 0.952\n",
      "Epoch 261/1000,  Loss: 0.2018,  Accuracy: 0.952\n",
      "Epoch 262/1000,  Loss: 0.2014,  Accuracy: 0.952\n",
      "Epoch 263/1000,  Loss: 0.201,  Accuracy: 0.952\n",
      "Epoch 264/1000,  Loss: 0.2006,  Accuracy: 0.952\n",
      "Epoch 265/1000,  Loss: 0.2001,  Accuracy: 0.952\n",
      "Epoch 266/1000,  Loss: 0.1997,  Accuracy: 0.952\n",
      "Epoch 267/1000,  Loss: 0.1993,  Accuracy: 0.952\n",
      "Epoch 268/1000,  Loss: 0.1989,  Accuracy: 0.952\n",
      "Epoch 269/1000,  Loss: 0.1985,  Accuracy: 0.952\n",
      "Epoch 270/1000,  Loss: 0.1981,  Accuracy: 0.952\n",
      "Epoch 271/1000,  Loss: 0.1977,  Accuracy: 0.952\n",
      "Epoch 272/1000,  Loss: 0.1973,  Accuracy: 0.952\n",
      "Epoch 273/1000,  Loss: 0.1969,  Accuracy: 0.952\n",
      "Epoch 274/1000,  Loss: 0.1965,  Accuracy: 0.952\n",
      "Epoch 275/1000,  Loss: 0.1961,  Accuracy: 0.952\n",
      "Epoch 276/1000,  Loss: 0.1958,  Accuracy: 0.952\n",
      "Epoch 277/1000,  Loss: 0.1954,  Accuracy: 0.952\n",
      "Epoch 278/1000,  Loss: 0.195,  Accuracy: 0.952\n",
      "Epoch 279/1000,  Loss: 0.1946,  Accuracy: 0.952\n",
      "Epoch 280/1000,  Loss: 0.1942,  Accuracy: 0.952\n",
      "Epoch 281/1000,  Loss: 0.1939,  Accuracy: 0.952\n",
      "Epoch 282/1000,  Loss: 0.1935,  Accuracy: 0.952\n",
      "Epoch 283/1000,  Loss: 0.1931,  Accuracy: 0.952\n",
      "Epoch 284/1000,  Loss: 0.1927,  Accuracy: 0.952\n",
      "Epoch 285/1000,  Loss: 0.1924,  Accuracy: 0.952\n",
      "Epoch 286/1000,  Loss: 0.192,  Accuracy: 0.952\n",
      "Epoch 287/1000,  Loss: 0.1916,  Accuracy: 0.952\n",
      "Epoch 288/1000,  Loss: 0.1913,  Accuracy: 0.952\n",
      "Epoch 289/1000,  Loss: 0.1909,  Accuracy: 0.952\n",
      "Epoch 290/1000,  Loss: 0.1905,  Accuracy: 0.952\n",
      "Epoch 291/1000,  Loss: 0.1902,  Accuracy: 0.952\n",
      "Epoch 292/1000,  Loss: 0.1898,  Accuracy: 0.952\n",
      "Epoch 293/1000,  Loss: 0.1895,  Accuracy: 0.954\n",
      "Epoch 294/1000,  Loss: 0.1891,  Accuracy: 0.954\n",
      "Epoch 295/1000,  Loss: 0.1888,  Accuracy: 0.954\n",
      "Epoch 296/1000,  Loss: 0.1884,  Accuracy: 0.954\n",
      "Epoch 297/1000,  Loss: 0.1881,  Accuracy: 0.954\n",
      "Epoch 298/1000,  Loss: 0.1877,  Accuracy: 0.954\n",
      "Epoch 299/1000,  Loss: 0.1874,  Accuracy: 0.954\n",
      "Epoch 300/1000,  Loss: 0.1871,  Accuracy: 0.956\n",
      "Epoch 301/1000,  Loss: 0.1867,  Accuracy: 0.956\n",
      "Epoch 302/1000,  Loss: 0.1864,  Accuracy: 0.956\n",
      "Epoch 303/1000,  Loss: 0.186,  Accuracy: 0.956\n",
      "Epoch 304/1000,  Loss: 0.1857,  Accuracy: 0.956\n",
      "Epoch 305/1000,  Loss: 0.1854,  Accuracy: 0.956\n",
      "Epoch 306/1000,  Loss: 0.185,  Accuracy: 0.956\n",
      "Epoch 307/1000,  Loss: 0.1847,  Accuracy: 0.956\n",
      "Epoch 308/1000,  Loss: 0.1844,  Accuracy: 0.956\n",
      "Epoch 309/1000,  Loss: 0.1841,  Accuracy: 0.956\n",
      "Epoch 310/1000,  Loss: 0.1837,  Accuracy: 0.956\n",
      "Epoch 311/1000,  Loss: 0.1834,  Accuracy: 0.956\n",
      "Epoch 312/1000,  Loss: 0.1831,  Accuracy: 0.956\n",
      "Epoch 313/1000,  Loss: 0.1828,  Accuracy: 0.956\n",
      "Epoch 314/1000,  Loss: 0.1825,  Accuracy: 0.956\n",
      "Epoch 315/1000,  Loss: 0.1821,  Accuracy: 0.956\n",
      "Epoch 316/1000,  Loss: 0.1818,  Accuracy: 0.956\n",
      "Epoch 317/1000,  Loss: 0.1815,  Accuracy: 0.956\n",
      "Epoch 318/1000,  Loss: 0.1812,  Accuracy: 0.956\n",
      "Epoch 319/1000,  Loss: 0.1809,  Accuracy: 0.956\n",
      "Epoch 320/1000,  Loss: 0.1806,  Accuracy: 0.956\n",
      "Epoch 321/1000,  Loss: 0.1803,  Accuracy: 0.956\n",
      "Epoch 322/1000,  Loss: 0.18,  Accuracy: 0.956\n",
      "Epoch 323/1000,  Loss: 0.1797,  Accuracy: 0.956\n",
      "Epoch 324/1000,  Loss: 0.1794,  Accuracy: 0.956\n",
      "Epoch 325/1000,  Loss: 0.1791,  Accuracy: 0.956\n",
      "Epoch 326/1000,  Loss: 0.1788,  Accuracy: 0.956\n",
      "Epoch 327/1000,  Loss: 0.1785,  Accuracy: 0.956\n",
      "Epoch 328/1000,  Loss: 0.1782,  Accuracy: 0.956\n",
      "Epoch 329/1000,  Loss: 0.1779,  Accuracy: 0.956\n",
      "Epoch 330/1000,  Loss: 0.1776,  Accuracy: 0.956\n",
      "Epoch 331/1000,  Loss: 0.1773,  Accuracy: 0.956\n",
      "Epoch 332/1000,  Loss: 0.177,  Accuracy: 0.956\n",
      "Epoch 333/1000,  Loss: 0.1767,  Accuracy: 0.956\n",
      "Epoch 334/1000,  Loss: 0.1764,  Accuracy: 0.956\n",
      "Epoch 335/1000,  Loss: 0.1761,  Accuracy: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 569/1000 [00:00<00:00, 1907.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000,  Loss: 0.1758,  Accuracy: 0.956\n",
      "Epoch 337/1000,  Loss: 0.1756,  Accuracy: 0.956\n",
      "Epoch 338/1000,  Loss: 0.1753,  Accuracy: 0.956\n",
      "Epoch 339/1000,  Loss: 0.175,  Accuracy: 0.956\n",
      "Epoch 340/1000,  Loss: 0.1747,  Accuracy: 0.956\n",
      "Epoch 341/1000,  Loss: 0.1744,  Accuracy: 0.958\n",
      "Epoch 342/1000,  Loss: 0.1741,  Accuracy: 0.958\n",
      "Epoch 343/1000,  Loss: 0.1739,  Accuracy: 0.958\n",
      "Epoch 344/1000,  Loss: 0.1736,  Accuracy: 0.958\n",
      "Epoch 345/1000,  Loss: 0.1733,  Accuracy: 0.958\n",
      "Epoch 346/1000,  Loss: 0.173,  Accuracy: 0.958\n",
      "Epoch 347/1000,  Loss: 0.1728,  Accuracy: 0.958\n",
      "Epoch 348/1000,  Loss: 0.1725,  Accuracy: 0.958\n",
      "Epoch 349/1000,  Loss: 0.1722,  Accuracy: 0.958\n",
      "Epoch 350/1000,  Loss: 0.172,  Accuracy: 0.958\n",
      "Epoch 351/1000,  Loss: 0.1717,  Accuracy: 0.958\n",
      "Epoch 352/1000,  Loss: 0.1714,  Accuracy: 0.958\n",
      "Epoch 353/1000,  Loss: 0.1712,  Accuracy: 0.958\n",
      "Epoch 354/1000,  Loss: 0.1709,  Accuracy: 0.958\n",
      "Epoch 355/1000,  Loss: 0.1706,  Accuracy: 0.958\n",
      "Epoch 356/1000,  Loss: 0.1704,  Accuracy: 0.958\n",
      "Epoch 357/1000,  Loss: 0.1701,  Accuracy: 0.958\n",
      "Epoch 358/1000,  Loss: 0.1699,  Accuracy: 0.958\n",
      "Epoch 359/1000,  Loss: 0.1696,  Accuracy: 0.958\n",
      "Epoch 360/1000,  Loss: 0.1693,  Accuracy: 0.958\n",
      "Epoch 361/1000,  Loss: 0.1691,  Accuracy: 0.958\n",
      "Epoch 362/1000,  Loss: 0.1688,  Accuracy: 0.958\n",
      "Epoch 363/1000,  Loss: 0.1686,  Accuracy: 0.958\n",
      "Epoch 364/1000,  Loss: 0.1683,  Accuracy: 0.958\n",
      "Epoch 365/1000,  Loss: 0.1681,  Accuracy: 0.958\n",
      "Epoch 366/1000,  Loss: 0.1678,  Accuracy: 0.958\n",
      "Epoch 367/1000,  Loss: 0.1676,  Accuracy: 0.958\n",
      "Epoch 368/1000,  Loss: 0.1673,  Accuracy: 0.958\n",
      "Epoch 369/1000,  Loss: 0.1671,  Accuracy: 0.958\n",
      "Epoch 370/1000,  Loss: 0.1668,  Accuracy: 0.958\n",
      "Epoch 371/1000,  Loss: 0.1666,  Accuracy: 0.958\n",
      "Epoch 372/1000,  Loss: 0.1663,  Accuracy: 0.958\n",
      "Epoch 373/1000,  Loss: 0.1661,  Accuracy: 0.96\n",
      "Epoch 374/1000,  Loss: 0.1659,  Accuracy: 0.96\n",
      "Epoch 375/1000,  Loss: 0.1656,  Accuracy: 0.96\n",
      "Epoch 376/1000,  Loss: 0.1654,  Accuracy: 0.96\n",
      "Epoch 377/1000,  Loss: 0.1651,  Accuracy: 0.96\n",
      "Epoch 378/1000,  Loss: 0.1649,  Accuracy: 0.96\n",
      "Epoch 379/1000,  Loss: 0.1647,  Accuracy: 0.96\n",
      "Epoch 380/1000,  Loss: 0.1644,  Accuracy: 0.96\n",
      "Epoch 381/1000,  Loss: 0.1642,  Accuracy: 0.96\n",
      "Epoch 382/1000,  Loss: 0.164,  Accuracy: 0.96\n",
      "Epoch 383/1000,  Loss: 0.1637,  Accuracy: 0.96\n",
      "Epoch 384/1000,  Loss: 0.1635,  Accuracy: 0.96\n",
      "Epoch 385/1000,  Loss: 0.1633,  Accuracy: 0.96\n",
      "Epoch 386/1000,  Loss: 0.163,  Accuracy: 0.96\n",
      "Epoch 387/1000,  Loss: 0.1628,  Accuracy: 0.96\n",
      "Epoch 388/1000,  Loss: 0.1626,  Accuracy: 0.96\n",
      "Epoch 389/1000,  Loss: 0.1624,  Accuracy: 0.96\n",
      "Epoch 390/1000,  Loss: 0.1621,  Accuracy: 0.96\n",
      "Epoch 391/1000,  Loss: 0.1619,  Accuracy: 0.96\n",
      "Epoch 392/1000,  Loss: 0.1617,  Accuracy: 0.96\n",
      "Epoch 393/1000,  Loss: 0.1615,  Accuracy: 0.96\n",
      "Epoch 394/1000,  Loss: 0.1612,  Accuracy: 0.96\n",
      "Epoch 395/1000,  Loss: 0.161,  Accuracy: 0.963\n",
      "Epoch 396/1000,  Loss: 0.1608,  Accuracy: 0.963\n",
      "Epoch 397/1000,  Loss: 0.1606,  Accuracy: 0.963\n",
      "Epoch 398/1000,  Loss: 0.1603,  Accuracy: 0.963\n",
      "Epoch 399/1000,  Loss: 0.1601,  Accuracy: 0.963\n",
      "Epoch 400/1000,  Loss: 0.1599,  Accuracy: 0.963\n",
      "Epoch 401/1000,  Loss: 0.1597,  Accuracy: 0.963\n",
      "Epoch 402/1000,  Loss: 0.1595,  Accuracy: 0.963\n",
      "Epoch 403/1000,  Loss: 0.1593,  Accuracy: 0.963\n",
      "Epoch 404/1000,  Loss: 0.159,  Accuracy: 0.963\n",
      "Epoch 405/1000,  Loss: 0.1588,  Accuracy: 0.963\n",
      "Epoch 406/1000,  Loss: 0.1586,  Accuracy: 0.963\n",
      "Epoch 407/1000,  Loss: 0.1584,  Accuracy: 0.963\n",
      "Epoch 408/1000,  Loss: 0.1582,  Accuracy: 0.963\n",
      "Epoch 409/1000,  Loss: 0.158,  Accuracy: 0.963\n",
      "Epoch 410/1000,  Loss: 0.1578,  Accuracy: 0.963\n",
      "Epoch 411/1000,  Loss: 0.1576,  Accuracy: 0.963\n",
      "Epoch 412/1000,  Loss: 0.1574,  Accuracy: 0.963\n",
      "Epoch 413/1000,  Loss: 0.1572,  Accuracy: 0.963\n",
      "Epoch 414/1000,  Loss: 0.1569,  Accuracy: 0.963\n",
      "Epoch 415/1000,  Loss: 0.1567,  Accuracy: 0.963\n",
      "Epoch 416/1000,  Loss: 0.1565,  Accuracy: 0.963\n",
      "Epoch 417/1000,  Loss: 0.1563,  Accuracy: 0.963\n",
      "Epoch 418/1000,  Loss: 0.1561,  Accuracy: 0.963\n",
      "Epoch 419/1000,  Loss: 0.1559,  Accuracy: 0.963\n",
      "Epoch 420/1000,  Loss: 0.1557,  Accuracy: 0.963\n",
      "Epoch 421/1000,  Loss: 0.1555,  Accuracy: 0.963\n",
      "Epoch 422/1000,  Loss: 0.1553,  Accuracy: 0.963\n",
      "Epoch 423/1000,  Loss: 0.1551,  Accuracy: 0.963\n",
      "Epoch 424/1000,  Loss: 0.1549,  Accuracy: 0.965\n",
      "Epoch 425/1000,  Loss: 0.1547,  Accuracy: 0.965\n",
      "Epoch 426/1000,  Loss: 0.1545,  Accuracy: 0.965\n",
      "Epoch 427/1000,  Loss: 0.1543,  Accuracy: 0.965\n",
      "Epoch 428/1000,  Loss: 0.1541,  Accuracy: 0.965\n",
      "Epoch 429/1000,  Loss: 0.154,  Accuracy: 0.965\n",
      "Epoch 430/1000,  Loss: 0.1538,  Accuracy: 0.965\n",
      "Epoch 431/1000,  Loss: 0.1536,  Accuracy: 0.965\n",
      "Epoch 432/1000,  Loss: 0.1534,  Accuracy: 0.965\n",
      "Epoch 433/1000,  Loss: 0.1532,  Accuracy: 0.965\n",
      "Epoch 434/1000,  Loss: 0.153,  Accuracy: 0.965\n",
      "Epoch 435/1000,  Loss: 0.1528,  Accuracy: 0.965\n",
      "Epoch 436/1000,  Loss: 0.1526,  Accuracy: 0.965\n",
      "Epoch 437/1000,  Loss: 0.1524,  Accuracy: 0.965\n",
      "Epoch 438/1000,  Loss: 0.1522,  Accuracy: 0.965\n",
      "Epoch 439/1000,  Loss: 0.152,  Accuracy: 0.965\n",
      "Epoch 440/1000,  Loss: 0.1519,  Accuracy: 0.965\n",
      "Epoch 441/1000,  Loss: 0.1517,  Accuracy: 0.965\n",
      "Epoch 442/1000,  Loss: 0.1515,  Accuracy: 0.967\n",
      "Epoch 443/1000,  Loss: 0.1513,  Accuracy: 0.967\n",
      "Epoch 444/1000,  Loss: 0.1511,  Accuracy: 0.967\n",
      "Epoch 445/1000,  Loss: 0.1509,  Accuracy: 0.967\n",
      "Epoch 446/1000,  Loss: 0.1507,  Accuracy: 0.967\n",
      "Epoch 447/1000,  Loss: 0.1506,  Accuracy: 0.967\n",
      "Epoch 448/1000,  Loss: 0.1504,  Accuracy: 0.967\n",
      "Epoch 449/1000,  Loss: 0.1502,  Accuracy: 0.967\n",
      "Epoch 450/1000,  Loss: 0.15,  Accuracy: 0.967\n",
      "Epoch 451/1000,  Loss: 0.1498,  Accuracy: 0.967\n",
      "Epoch 452/1000,  Loss: 0.1497,  Accuracy: 0.967\n",
      "Epoch 453/1000,  Loss: 0.1495,  Accuracy: 0.967\n",
      "Epoch 454/1000,  Loss: 0.1493,  Accuracy: 0.967\n",
      "Epoch 455/1000,  Loss: 0.1491,  Accuracy: 0.967\n",
      "Epoch 456/1000,  Loss: 0.149,  Accuracy: 0.967\n",
      "Epoch 457/1000,  Loss: 0.1488,  Accuracy: 0.967\n",
      "Epoch 458/1000,  Loss: 0.1486,  Accuracy: 0.967\n",
      "Epoch 459/1000,  Loss: 0.1484,  Accuracy: 0.967\n",
      "Epoch 460/1000,  Loss: 0.1483,  Accuracy: 0.967\n",
      "Epoch 461/1000,  Loss: 0.1481,  Accuracy: 0.967\n",
      "Epoch 462/1000,  Loss: 0.1479,  Accuracy: 0.967\n",
      "Epoch 463/1000,  Loss: 0.1477,  Accuracy: 0.967\n",
      "Epoch 464/1000,  Loss: 0.1476,  Accuracy: 0.967\n",
      "Epoch 465/1000,  Loss: 0.1474,  Accuracy: 0.967\n",
      "Epoch 466/1000,  Loss: 0.1472,  Accuracy: 0.967\n",
      "Epoch 467/1000,  Loss: 0.147,  Accuracy: 0.967\n",
      "Epoch 468/1000,  Loss: 0.1469,  Accuracy: 0.967\n",
      "Epoch 469/1000,  Loss: 0.1467,  Accuracy: 0.967\n",
      "Epoch 470/1000,  Loss: 0.1465,  Accuracy: 0.967\n",
      "Epoch 471/1000,  Loss: 0.1464,  Accuracy: 0.967\n",
      "Epoch 472/1000,  Loss: 0.1462,  Accuracy: 0.967\n",
      "Epoch 473/1000,  Loss: 0.146,  Accuracy: 0.967\n",
      "Epoch 474/1000,  Loss: 0.1459,  Accuracy: 0.967\n",
      "Epoch 475/1000,  Loss: 0.1457,  Accuracy: 0.967\n",
      "Epoch 476/1000,  Loss: 0.1455,  Accuracy: 0.967\n",
      "Epoch 477/1000,  Loss: 0.1454,  Accuracy: 0.967\n",
      "Epoch 478/1000,  Loss: 0.1452,  Accuracy: 0.967\n",
      "Epoch 479/1000,  Loss: 0.1451,  Accuracy: 0.967\n",
      "Epoch 480/1000,  Loss: 0.1449,  Accuracy: 0.967\n",
      "Epoch 481/1000,  Loss: 0.1447,  Accuracy: 0.967\n",
      "Epoch 482/1000,  Loss: 0.1446,  Accuracy: 0.967\n",
      "Epoch 483/1000,  Loss: 0.1444,  Accuracy: 0.967\n",
      "Epoch 484/1000,  Loss: 0.1442,  Accuracy: 0.967\n",
      "Epoch 485/1000,  Loss: 0.1441,  Accuracy: 0.967\n",
      "Epoch 486/1000,  Loss: 0.1439,  Accuracy: 0.967\n",
      "Epoch 487/1000,  Loss: 0.1438,  Accuracy: 0.967\n",
      "Epoch 488/1000,  Loss: 0.1436,  Accuracy: 0.967\n",
      "Epoch 489/1000,  Loss: 0.1434,  Accuracy: 0.967\n",
      "Epoch 490/1000,  Loss: 0.1433,  Accuracy: 0.967\n",
      "Epoch 491/1000,  Loss: 0.1431,  Accuracy: 0.967\n",
      "Epoch 492/1000,  Loss: 0.143,  Accuracy: 0.967\n",
      "Epoch 493/1000,  Loss: 0.1428,  Accuracy: 0.967\n",
      "Epoch 494/1000,  Loss: 0.1427,  Accuracy: 0.967\n",
      "Epoch 495/1000,  Loss: 0.1425,  Accuracy: 0.967\n",
      "Epoch 496/1000,  Loss: 0.1424,  Accuracy: 0.967\n",
      "Epoch 497/1000,  Loss: 0.1422,  Accuracy: 0.967\n",
      "Epoch 498/1000,  Loss: 0.142,  Accuracy: 0.967\n",
      "Epoch 499/1000,  Loss: 0.1419,  Accuracy: 0.967\n",
      "Epoch 500/1000,  Loss: 0.1417,  Accuracy: 0.967\n",
      "Epoch 501/1000,  Loss: 0.1416,  Accuracy: 0.967\n",
      "Epoch 502/1000,  Loss: 0.1414,  Accuracy: 0.967\n",
      "Epoch 503/1000,  Loss: 0.1413,  Accuracy: 0.967\n",
      "Epoch 504/1000,  Loss: 0.1411,  Accuracy: 0.967\n",
      "Epoch 505/1000,  Loss: 0.141,  Accuracy: 0.967\n",
      "Epoch 506/1000,  Loss: 0.1408,  Accuracy: 0.967\n",
      "Epoch 507/1000,  Loss: 0.1407,  Accuracy: 0.967\n",
      "Epoch 508/1000,  Loss: 0.1405,  Accuracy: 0.967\n",
      "Epoch 509/1000,  Loss: 0.1404,  Accuracy: 0.967\n",
      "Epoch 510/1000,  Loss: 0.1402,  Accuracy: 0.967\n",
      "Epoch 511/1000,  Loss: 0.1401,  Accuracy: 0.967\n",
      "Epoch 512/1000,  Loss: 0.14,  Accuracy: 0.967\n",
      "Epoch 513/1000,  Loss: 0.1398,  Accuracy: 0.967\n",
      "Epoch 514/1000,  Loss: 0.1397,  Accuracy: 0.967\n",
      "Epoch 515/1000,  Loss: 0.1395,  Accuracy: 0.967\n",
      "Epoch 516/1000,  Loss: 0.1394,  Accuracy: 0.967\n",
      "Epoch 517/1000,  Loss: 0.1392,  Accuracy: 0.967\n",
      "Epoch 518/1000,  Loss: 0.1391,  Accuracy: 0.967\n",
      "Epoch 519/1000,  Loss: 0.1389,  Accuracy: 0.967\n",
      "Epoch 520/1000,  Loss: 0.1388,  Accuracy: 0.967\n",
      "Epoch 521/1000,  Loss: 0.1387,  Accuracy: 0.967\n",
      "Epoch 522/1000,  Loss: 0.1385,  Accuracy: 0.967\n",
      "Epoch 523/1000,  Loss: 0.1384,  Accuracy: 0.967\n",
      "Epoch 524/1000,  Loss: 0.1382,  Accuracy: 0.967\n",
      "Epoch 525/1000,  Loss: 0.1381,  Accuracy: 0.967\n",
      "Epoch 526/1000,  Loss: 0.1379,  Accuracy: 0.967\n",
      "Epoch 527/1000,  Loss: 0.1378,  Accuracy: 0.967\n",
      "Epoch 528/1000,  Loss: 0.1377,  Accuracy: 0.967\n",
      "Epoch 529/1000,  Loss: 0.1375,  Accuracy: 0.967\n",
      "Epoch 530/1000,  Loss: 0.1374,  Accuracy: 0.967\n",
      "Epoch 531/1000,  Loss: 0.1372,  Accuracy: 0.967\n",
      "Epoch 532/1000,  Loss: 0.1371,  Accuracy: 0.967\n",
      "Epoch 533/1000,  Loss: 0.137,  Accuracy: 0.967\n",
      "Epoch 534/1000,  Loss: 0.1368,  Accuracy: 0.967\n",
      "Epoch 535/1000,  Loss: 0.1367,  Accuracy: 0.967\n",
      "Epoch 536/1000,  Loss: 0.1366,  Accuracy: 0.967\n",
      "Epoch 537/1000,  Loss: 0.1364,  Accuracy: 0.967\n",
      "Epoch 538/1000,  Loss: 0.1363,  Accuracy: 0.967\n",
      "Epoch 539/1000,  Loss: 0.1362,  Accuracy: 0.967\n",
      "Epoch 540/1000,  Loss: 0.136,  Accuracy: 0.969\n",
      "Epoch 541/1000,  Loss: 0.1359,  Accuracy: 0.969\n",
      "Epoch 542/1000,  Loss: 0.1358,  Accuracy: 0.969\n",
      "Epoch 543/1000,  Loss: 0.1356,  Accuracy: 0.969\n",
      "Epoch 544/1000,  Loss: 0.1355,  Accuracy: 0.969\n",
      "Epoch 545/1000,  Loss: 0.1354,  Accuracy: 0.969\n",
      "Epoch 546/1000,  Loss: 0.1352,  Accuracy: 0.969\n",
      "Epoch 547/1000,  Loss: 0.1351,  Accuracy: 0.969\n",
      "Epoch 548/1000,  Loss: 0.135,  Accuracy: 0.969\n",
      "Epoch 549/1000,  Loss: 0.1348,  Accuracy: 0.969\n",
      "Epoch 550/1000,  Loss: 0.1347,  Accuracy: 0.969\n",
      "Epoch 551/1000,  Loss: 0.1346,  Accuracy: 0.969\n",
      "Epoch 552/1000,  Loss: 0.1344,  Accuracy: 0.969\n",
      "Epoch 553/1000,  Loss: 0.1343,  Accuracy: 0.969\n",
      "Epoch 554/1000,  Loss: 0.1342,  Accuracy: 0.969\n",
      "Epoch 555/1000,  Loss: 0.134,  Accuracy: 0.969\n",
      "Epoch 556/1000,  Loss: 0.1339,  Accuracy: 0.969\n",
      "Epoch 557/1000,  Loss: 0.1338,  Accuracy: 0.969\n",
      "Epoch 558/1000,  Loss: 0.1337,  Accuracy: 0.969\n",
      "Epoch 559/1000,  Loss: 0.1335,  Accuracy: 0.969\n",
      "Epoch 560/1000,  Loss: 0.1334,  Accuracy: 0.969\n",
      "Epoch 561/1000,  Loss: 0.1333,  Accuracy: 0.969\n",
      "Epoch 562/1000,  Loss: 0.1332,  Accuracy: 0.969\n",
      "Epoch 563/1000,  Loss: 0.133,  Accuracy: 0.969\n",
      "Epoch 564/1000,  Loss: 0.1329,  Accuracy: 0.969\n",
      "Epoch 565/1000,  Loss: 0.1328,  Accuracy: 0.969\n",
      "Epoch 566/1000,  Loss: 0.1327,  Accuracy: 0.969\n",
      "Epoch 567/1000,  Loss: 0.1325,  Accuracy: 0.969\n",
      "Epoch 568/1000,  Loss: 0.1324,  Accuracy: 0.969\n",
      "Epoch 569/1000,  Loss: 0.1323,  Accuracy: 0.969\n",
      "Epoch 570/1000,  Loss: 0.1322,  Accuracy: 0.971\n",
      "Epoch 571/1000,  Loss: 0.132,  Accuracy: 0.971\n",
      "Epoch 572/1000,  Loss: 0.1319,  Accuracy: 0.971\n",
      "Epoch 573/1000,  Loss: 0.1318,  Accuracy: 0.974\n",
      "Epoch 574/1000,  Loss: 0.1317,  Accuracy: 0.974\n",
      "Epoch 575/1000,  Loss: 0.1315,  Accuracy: 0.974\n",
      "Epoch 576/1000,  Loss: 0.1314,  Accuracy: 0.974\n",
      "Epoch 577/1000,  Loss: 0.1313,  Accuracy: 0.974\n",
      "Epoch 578/1000,  Loss: 0.1312,  Accuracy: 0.974\n",
      "Epoch 579/1000,  Loss: 0.1311,  Accuracy: 0.974\n",
      "Epoch 580/1000,  Loss: 0.1309,  Accuracy: 0.974\n",
      "Epoch 581/1000,  Loss: 0.1308,  Accuracy: 0.974\n",
      "Epoch 582/1000,  Loss: 0.1307,  Accuracy: 0.974\n",
      "Epoch 583/1000,  Loss: 0.1306,  Accuracy: 0.974\n",
      "Epoch 584/1000,  Loss: 0.1305,  Accuracy: 0.974\n",
      "Epoch 585/1000,  Loss: 0.1303,  Accuracy: 0.974\n",
      "Epoch 586/1000,  Loss: 0.1302,  Accuracy: 0.974\n",
      "Epoch 587/1000,  Loss: 0.1301,  Accuracy: 0.974\n",
      "Epoch 588/1000,  Loss: 0.13,  Accuracy: 0.974\n",
      "Epoch 589/1000,  Loss: 0.1299,  Accuracy: 0.974\n",
      "Epoch 590/1000,  Loss: 0.1298,  Accuracy: 0.974\n",
      "Epoch 591/1000,  Loss: 0.1296,  Accuracy: 0.974\n",
      "Epoch 592/1000,  Loss: 0.1295,  Accuracy: 0.974\n",
      "Epoch 593/1000,  Loss: 0.1294,  Accuracy: 0.974\n",
      "Epoch 594/1000,  Loss: 0.1293,  Accuracy: 0.974\n",
      "Epoch 595/1000,  Loss: 0.1292,  Accuracy: 0.974\n",
      "Epoch 596/1000,  Loss: 0.1291,  Accuracy: 0.974\n",
      "Epoch 597/1000,  Loss: 0.1289,  Accuracy: 0.974\n",
      "Epoch 598/1000,  Loss: 0.1288,  Accuracy: 0.974\n",
      "Epoch 599/1000,  Loss: 0.1287,  Accuracy: 0.974\n",
      "Epoch 600/1000,  Loss: 0.1286,  Accuracy: 0.974\n",
      "Epoch 601/1000,  Loss: 0.1285,  Accuracy: 0.974\n",
      "Epoch 602/1000,  Loss: 0.1284,  Accuracy: 0.974\n",
      "Epoch 603/1000,  Loss: 0.1283,  Accuracy: 0.974\n",
      "Epoch 604/1000,  Loss: 0.1282,  Accuracy: 0.974\n",
      "Epoch 605/1000,  Loss: 0.128,  Accuracy: 0.974\n",
      "Epoch 606/1000,  Loss: 0.1279,  Accuracy: 0.974\n",
      "Epoch 607/1000,  Loss: 0.1278,  Accuracy: 0.974\n",
      "Epoch 608/1000,  Loss: 0.1277,  Accuracy: 0.974\n",
      "Epoch 609/1000,  Loss: 0.1276,  Accuracy: 0.974\n",
      "Epoch 610/1000,  Loss: 0.1275,  Accuracy: 0.974\n",
      "Epoch 611/1000,  Loss: 0.1274,  Accuracy: 0.974\n",
      "Epoch 612/1000,  Loss: 0.1273,  Accuracy: 0.974\n",
      "Epoch 613/1000,  Loss: 0.1272,  Accuracy: 0.974\n",
      "Epoch 614/1000,  Loss: 0.127,  Accuracy: 0.974\n",
      "Epoch 615/1000,  Loss: 0.1269,  Accuracy: 0.974\n",
      "Epoch 616/1000,  Loss: 0.1268,  Accuracy: 0.974\n",
      "Epoch 617/1000,  Loss: 0.1267,  Accuracy: 0.974\n",
      "Epoch 618/1000,  Loss: 0.1266,  Accuracy: 0.974\n",
      "Epoch 619/1000,  Loss: 0.1265,  Accuracy: 0.974\n",
      "Epoch 620/1000,  Loss: 0.1264,  Accuracy: 0.974\n",
      "Epoch 621/1000,  Loss: 0.1263,  Accuracy: 0.974\n",
      "Epoch 622/1000,  Loss: 0.1262,  Accuracy: 0.974\n",
      "Epoch 623/1000,  Loss: 0.1261,  Accuracy: 0.974\n",
      "Epoch 624/1000,  Loss: 0.126,  Accuracy: 0.974\n",
      "Epoch 625/1000,  Loss: 0.1259,  Accuracy: 0.974\n",
      "Epoch 626/1000,  Loss: 0.1258,  Accuracy: 0.974\n",
      "Epoch 627/1000,  Loss: 0.1256,  Accuracy: 0.974\n",
      "Epoch 628/1000,  Loss: 0.1255,  Accuracy: 0.974\n",
      "Epoch 629/1000,  Loss: 0.1254,  Accuracy: 0.974\n",
      "Epoch 630/1000,  Loss: 0.1253,  Accuracy: 0.974\n",
      "Epoch 631/1000,  Loss: 0.1252,  Accuracy: 0.974\n",
      "Epoch 632/1000,  Loss: 0.1251,  Accuracy: 0.974\n",
      "Epoch 633/1000,  Loss: 0.125,  Accuracy: 0.974\n",
      "Epoch 634/1000,  Loss: 0.1249,  Accuracy: 0.974\n",
      "Epoch 635/1000,  Loss: 0.1248,  Accuracy: 0.974\n",
      "Epoch 636/1000,  Loss: 0.1247,  Accuracy: 0.974\n",
      "Epoch 637/1000,  Loss: 0.1246,  Accuracy: 0.974\n",
      "Epoch 638/1000,  Loss: 0.1245,  Accuracy: 0.974\n",
      "Epoch 639/1000,  Loss: 0.1244,  Accuracy: 0.974\n",
      "Epoch 640/1000,  Loss: 0.1243,  Accuracy: 0.974\n",
      "Epoch 641/1000,  Loss: 0.1242,  Accuracy: 0.974\n",
      "Epoch 642/1000,  Loss: 0.1241,  Accuracy: 0.974\n",
      "Epoch 643/1000,  Loss: 0.124,  Accuracy: 0.974\n",
      "Epoch 644/1000,  Loss: 0.1239,  Accuracy: 0.974\n",
      "Epoch 645/1000,  Loss: 0.1238,  Accuracy: 0.974\n",
      "Epoch 646/1000,  Loss: 0.1237,  Accuracy: 0.974\n",
      "Epoch 647/1000,  Loss: 0.1236,  Accuracy: 0.974\n",
      "Epoch 648/1000,  Loss: 0.1235,  Accuracy: 0.974\n",
      "Epoch 649/1000,  Loss: 0.1234,  Accuracy: 0.974\n",
      "Epoch 650/1000,  Loss: 0.1233,  Accuracy: 0.974\n",
      "Epoch 651/1000,  Loss: 0.1232,  Accuracy: 0.974\n",
      "Epoch 652/1000,  Loss: 0.1231,  Accuracy: 0.974\n",
      "Epoch 653/1000,  Loss: 0.123,  Accuracy: 0.974\n",
      "Epoch 654/1000,  Loss: 0.1229,  Accuracy: 0.974\n",
      "Epoch 655/1000,  Loss: 0.1228,  Accuracy: 0.974\n",
      "Epoch 656/1000,  Loss: 0.1227,  Accuracy: 0.974\n",
      "Epoch 657/1000,  Loss: 0.1226,  Accuracy: 0.974\n",
      "Epoch 658/1000,  Loss: 0.1225,  Accuracy: 0.974\n",
      "Epoch 659/1000,  Loss: 0.1224,  Accuracy: 0.974\n",
      "Epoch 660/1000,  Loss: 0.1223,  Accuracy: 0.974\n",
      "Epoch 661/1000,  Loss: 0.1222,  Accuracy: 0.974\n",
      "Epoch 662/1000,  Loss: 0.1221,  Accuracy: 0.974\n",
      "Epoch 663/1000,  Loss: 0.122,  Accuracy: 0.974\n",
      "Epoch 664/1000,  Loss: 0.1219,  Accuracy: 0.974\n",
      "Epoch 665/1000,  Loss: 0.1218,  Accuracy: 0.974\n",
      "Epoch 666/1000,  Loss: 0.1217,  Accuracy: 0.974\n",
      "Epoch 667/1000,  Loss: 0.1216,  Accuracy: 0.974\n",
      "Epoch 668/1000,  Loss: 0.1215,  Accuracy: 0.974\n",
      "Epoch 669/1000,  Loss: 0.1214,  Accuracy: 0.974\n",
      "Epoch 670/1000,  Loss: 0.1213,  Accuracy: 0.974\n",
      "Epoch 671/1000,  Loss: 0.1212,  Accuracy: 0.974\n",
      "Epoch 672/1000,  Loss: 0.1211,  Accuracy: 0.974\n",
      "Epoch 673/1000,  Loss: 0.1211,  Accuracy: 0.974\n",
      "Epoch 674/1000,  Loss: 0.121,  Accuracy: 0.974\n",
      "Epoch 675/1000,  Loss: 0.1209,  Accuracy: 0.974\n",
      "Epoch 676/1000,  Loss: 0.1208,  Accuracy: 0.974\n",
      "Epoch 677/1000,  Loss: 0.1207,  Accuracy: 0.974\n",
      "Epoch 678/1000,  Loss: 0.1206,  Accuracy: 0.974\n",
      "Epoch 679/1000,  Loss: 0.1205,  Accuracy: 0.974\n",
      "Epoch 680/1000,  Loss: 0.1204,  Accuracy: 0.974\n",
      "Epoch 681/1000,  Loss: 0.1203,  Accuracy: 0.974\n",
      "Epoch 682/1000,  Loss: 0.1202,  Accuracy: 0.974\n",
      "Epoch 683/1000,  Loss: 0.1201,  Accuracy: 0.974\n",
      "Epoch 684/1000,  Loss: 0.12,  Accuracy: 0.974\n",
      "Epoch 685/1000,  Loss: 0.1199,  Accuracy: 0.974\n",
      "Epoch 686/1000,  Loss: 0.1198,  Accuracy: 0.974\n",
      "Epoch 687/1000,  Loss: 0.1198,  Accuracy: 0.974\n",
      "Epoch 688/1000,  Loss: 0.1197,  Accuracy: 0.974\n",
      "Epoch 689/1000,  Loss: 0.1196,  Accuracy: 0.974\n",
      "Epoch 690/1000,  Loss: 0.1195,  Accuracy: 0.974\n",
      "Epoch 691/1000,  Loss: 0.1194,  Accuracy: 0.974\n",
      "Epoch 692/1000,  Loss: 0.1193,  Accuracy: 0.974\n",
      "Epoch 693/1000,  Loss: 0.1192,  Accuracy: 0.974\n",
      "Epoch 694/1000,  Loss: 0.1191,  Accuracy: 0.976\n",
      "Epoch 695/1000,  Loss: 0.119,  Accuracy: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1915.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/1000,  Loss: 0.1189,  Accuracy: 0.976\n",
      "Epoch 697/1000,  Loss: 0.1189,  Accuracy: 0.976\n",
      "Epoch 698/1000,  Loss: 0.1188,  Accuracy: 0.976\n",
      "Epoch 699/1000,  Loss: 0.1187,  Accuracy: 0.976\n",
      "Epoch 700/1000,  Loss: 0.1186,  Accuracy: 0.976\n",
      "Epoch 701/1000,  Loss: 0.1185,  Accuracy: 0.976\n",
      "Epoch 702/1000,  Loss: 0.1184,  Accuracy: 0.976\n",
      "Epoch 703/1000,  Loss: 0.1183,  Accuracy: 0.976\n",
      "Epoch 704/1000,  Loss: 0.1182,  Accuracy: 0.976\n",
      "Epoch 705/1000,  Loss: 0.1181,  Accuracy: 0.976\n",
      "Epoch 706/1000,  Loss: 0.1181,  Accuracy: 0.976\n",
      "Epoch 707/1000,  Loss: 0.118,  Accuracy: 0.976\n",
      "Epoch 708/1000,  Loss: 0.1179,  Accuracy: 0.976\n",
      "Epoch 709/1000,  Loss: 0.1178,  Accuracy: 0.976\n",
      "Epoch 710/1000,  Loss: 0.1177,  Accuracy: 0.976\n",
      "Epoch 711/1000,  Loss: 0.1176,  Accuracy: 0.976\n",
      "Epoch 712/1000,  Loss: 0.1175,  Accuracy: 0.976\n",
      "Epoch 713/1000,  Loss: 0.1174,  Accuracy: 0.976\n",
      "Epoch 714/1000,  Loss: 0.1174,  Accuracy: 0.976\n",
      "Epoch 715/1000,  Loss: 0.1173,  Accuracy: 0.976\n",
      "Epoch 716/1000,  Loss: 0.1172,  Accuracy: 0.976\n",
      "Epoch 717/1000,  Loss: 0.1171,  Accuracy: 0.976\n",
      "Epoch 718/1000,  Loss: 0.117,  Accuracy: 0.976\n",
      "Epoch 719/1000,  Loss: 0.1169,  Accuracy: 0.976\n",
      "Epoch 720/1000,  Loss: 0.1169,  Accuracy: 0.976\n",
      "Epoch 721/1000,  Loss: 0.1168,  Accuracy: 0.976\n",
      "Epoch 722/1000,  Loss: 0.1167,  Accuracy: 0.976\n",
      "Epoch 723/1000,  Loss: 0.1166,  Accuracy: 0.976\n",
      "Epoch 724/1000,  Loss: 0.1165,  Accuracy: 0.976\n",
      "Epoch 725/1000,  Loss: 0.1164,  Accuracy: 0.976\n",
      "Epoch 726/1000,  Loss: 0.1163,  Accuracy: 0.976\n",
      "Epoch 727/1000,  Loss: 0.1163,  Accuracy: 0.976\n",
      "Epoch 728/1000,  Loss: 0.1162,  Accuracy: 0.976\n",
      "Epoch 729/1000,  Loss: 0.1161,  Accuracy: 0.976\n",
      "Epoch 730/1000,  Loss: 0.116,  Accuracy: 0.976\n",
      "Epoch 731/1000,  Loss: 0.1159,  Accuracy: 0.976\n",
      "Epoch 732/1000,  Loss: 0.1159,  Accuracy: 0.976\n",
      "Epoch 733/1000,  Loss: 0.1158,  Accuracy: 0.976\n",
      "Epoch 734/1000,  Loss: 0.1157,  Accuracy: 0.976\n",
      "Epoch 735/1000,  Loss: 0.1156,  Accuracy: 0.976\n",
      "Epoch 736/1000,  Loss: 0.1155,  Accuracy: 0.976\n",
      "Epoch 737/1000,  Loss: 0.1154,  Accuracy: 0.976\n",
      "Epoch 738/1000,  Loss: 0.1154,  Accuracy: 0.976\n",
      "Epoch 739/1000,  Loss: 0.1153,  Accuracy: 0.976\n",
      "Epoch 740/1000,  Loss: 0.1152,  Accuracy: 0.976\n",
      "Epoch 741/1000,  Loss: 0.1151,  Accuracy: 0.976\n",
      "Epoch 742/1000,  Loss: 0.115,  Accuracy: 0.976\n",
      "Epoch 743/1000,  Loss: 0.115,  Accuracy: 0.976\n",
      "Epoch 744/1000,  Loss: 0.1149,  Accuracy: 0.976\n",
      "Epoch 745/1000,  Loss: 0.1148,  Accuracy: 0.976\n",
      "Epoch 746/1000,  Loss: 0.1147,  Accuracy: 0.976\n",
      "Epoch 747/1000,  Loss: 0.1146,  Accuracy: 0.976\n",
      "Epoch 748/1000,  Loss: 0.1146,  Accuracy: 0.976\n",
      "Epoch 749/1000,  Loss: 0.1145,  Accuracy: 0.976\n",
      "Epoch 750/1000,  Loss: 0.1144,  Accuracy: 0.976\n",
      "Epoch 751/1000,  Loss: 0.1143,  Accuracy: 0.976\n",
      "Epoch 752/1000,  Loss: 0.1142,  Accuracy: 0.976\n",
      "Epoch 753/1000,  Loss: 0.1142,  Accuracy: 0.976\n",
      "Epoch 754/1000,  Loss: 0.1141,  Accuracy: 0.976\n",
      "Epoch 755/1000,  Loss: 0.114,  Accuracy: 0.976\n",
      "Epoch 756/1000,  Loss: 0.1139,  Accuracy: 0.976\n",
      "Epoch 757/1000,  Loss: 0.1138,  Accuracy: 0.976\n",
      "Epoch 758/1000,  Loss: 0.1138,  Accuracy: 0.976\n",
      "Epoch 759/1000,  Loss: 0.1137,  Accuracy: 0.976\n",
      "Epoch 760/1000,  Loss: 0.1136,  Accuracy: 0.976\n",
      "Epoch 761/1000,  Loss: 0.1135,  Accuracy: 0.976\n",
      "Epoch 762/1000,  Loss: 0.1135,  Accuracy: 0.976\n",
      "Epoch 763/1000,  Loss: 0.1134,  Accuracy: 0.976\n",
      "Epoch 764/1000,  Loss: 0.1133,  Accuracy: 0.976\n",
      "Epoch 765/1000,  Loss: 0.1132,  Accuracy: 0.976\n",
      "Epoch 766/1000,  Loss: 0.1132,  Accuracy: 0.978\n",
      "Epoch 767/1000,  Loss: 0.1131,  Accuracy: 0.978\n",
      "Epoch 768/1000,  Loss: 0.113,  Accuracy: 0.978\n",
      "Epoch 769/1000,  Loss: 0.1129,  Accuracy: 0.978\n",
      "Epoch 770/1000,  Loss: 0.1128,  Accuracy: 0.978\n",
      "Epoch 771/1000,  Loss: 0.1128,  Accuracy: 0.978\n",
      "Epoch 772/1000,  Loss: 0.1127,  Accuracy: 0.978\n",
      "Epoch 773/1000,  Loss: 0.1126,  Accuracy: 0.978\n",
      "Epoch 774/1000,  Loss: 0.1125,  Accuracy: 0.978\n",
      "Epoch 775/1000,  Loss: 0.1125,  Accuracy: 0.978\n",
      "Epoch 776/1000,  Loss: 0.1124,  Accuracy: 0.978\n",
      "Epoch 777/1000,  Loss: 0.1123,  Accuracy: 0.978\n",
      "Epoch 778/1000,  Loss: 0.1122,  Accuracy: 0.978\n",
      "Epoch 779/1000,  Loss: 0.1122,  Accuracy: 0.978\n",
      "Epoch 780/1000,  Loss: 0.1121,  Accuracy: 0.978\n",
      "Epoch 781/1000,  Loss: 0.112,  Accuracy: 0.978\n",
      "Epoch 782/1000,  Loss: 0.1119,  Accuracy: 0.978\n",
      "Epoch 783/1000,  Loss: 0.1119,  Accuracy: 0.978\n",
      "Epoch 784/1000,  Loss: 0.1118,  Accuracy: 0.978\n",
      "Epoch 785/1000,  Loss: 0.1117,  Accuracy: 0.978\n",
      "Epoch 786/1000,  Loss: 0.1117,  Accuracy: 0.98\n",
      "Epoch 787/1000,  Loss: 0.1116,  Accuracy: 0.98\n",
      "Epoch 788/1000,  Loss: 0.1115,  Accuracy: 0.98\n",
      "Epoch 789/1000,  Loss: 0.1114,  Accuracy: 0.98\n",
      "Epoch 790/1000,  Loss: 0.1114,  Accuracy: 0.98\n",
      "Epoch 791/1000,  Loss: 0.1113,  Accuracy: 0.98\n",
      "Epoch 792/1000,  Loss: 0.1112,  Accuracy: 0.98\n",
      "Epoch 793/1000,  Loss: 0.1111,  Accuracy: 0.98\n",
      "Epoch 794/1000,  Loss: 0.1111,  Accuracy: 0.98\n",
      "Epoch 795/1000,  Loss: 0.111,  Accuracy: 0.98\n",
      "Epoch 796/1000,  Loss: 0.1109,  Accuracy: 0.98\n",
      "Epoch 797/1000,  Loss: 0.1109,  Accuracy: 0.98\n",
      "Epoch 798/1000,  Loss: 0.1108,  Accuracy: 0.98\n",
      "Epoch 799/1000,  Loss: 0.1107,  Accuracy: 0.98\n",
      "Epoch 800/1000,  Loss: 0.1106,  Accuracy: 0.98\n",
      "Epoch 801/1000,  Loss: 0.1106,  Accuracy: 0.98\n",
      "Epoch 802/1000,  Loss: 0.1105,  Accuracy: 0.98\n",
      "Epoch 803/1000,  Loss: 0.1104,  Accuracy: 0.98\n",
      "Epoch 804/1000,  Loss: 0.1104,  Accuracy: 0.98\n",
      "Epoch 805/1000,  Loss: 0.1103,  Accuracy: 0.98\n",
      "Epoch 806/1000,  Loss: 0.1102,  Accuracy: 0.98\n",
      "Epoch 807/1000,  Loss: 0.1101,  Accuracy: 0.98\n",
      "Epoch 808/1000,  Loss: 0.1101,  Accuracy: 0.98\n",
      "Epoch 809/1000,  Loss: 0.11,  Accuracy: 0.98\n",
      "Epoch 810/1000,  Loss: 0.1099,  Accuracy: 0.98\n",
      "Epoch 811/1000,  Loss: 0.1099,  Accuracy: 0.98\n",
      "Epoch 812/1000,  Loss: 0.1098,  Accuracy: 0.98\n",
      "Epoch 813/1000,  Loss: 0.1097,  Accuracy: 0.98\n",
      "Epoch 814/1000,  Loss: 0.1097,  Accuracy: 0.98\n",
      "Epoch 815/1000,  Loss: 0.1096,  Accuracy: 0.98\n",
      "Epoch 816/1000,  Loss: 0.1095,  Accuracy: 0.98\n",
      "Epoch 817/1000,  Loss: 0.1094,  Accuracy: 0.98\n",
      "Epoch 818/1000,  Loss: 0.1094,  Accuracy: 0.98\n",
      "Epoch 819/1000,  Loss: 0.1093,  Accuracy: 0.98\n",
      "Epoch 820/1000,  Loss: 0.1092,  Accuracy: 0.98\n",
      "Epoch 821/1000,  Loss: 0.1092,  Accuracy: 0.98\n",
      "Epoch 822/1000,  Loss: 0.1091,  Accuracy: 0.98\n",
      "Epoch 823/1000,  Loss: 0.109,  Accuracy: 0.98\n",
      "Epoch 824/1000,  Loss: 0.109,  Accuracy: 0.98\n",
      "Epoch 825/1000,  Loss: 0.1089,  Accuracy: 0.98\n",
      "Epoch 826/1000,  Loss: 0.1088,  Accuracy: 0.98\n",
      "Epoch 827/1000,  Loss: 0.1088,  Accuracy: 0.98\n",
      "Epoch 828/1000,  Loss: 0.1087,  Accuracy: 0.98\n",
      "Epoch 829/1000,  Loss: 0.1086,  Accuracy: 0.982\n",
      "Epoch 830/1000,  Loss: 0.1086,  Accuracy: 0.982\n",
      "Epoch 831/1000,  Loss: 0.1085,  Accuracy: 0.982\n",
      "Epoch 832/1000,  Loss: 0.1084,  Accuracy: 0.982\n",
      "Epoch 833/1000,  Loss: 0.1084,  Accuracy: 0.982\n",
      "Epoch 834/1000,  Loss: 0.1083,  Accuracy: 0.982\n",
      "Epoch 835/1000,  Loss: 0.1082,  Accuracy: 0.982\n",
      "Epoch 836/1000,  Loss: 0.1082,  Accuracy: 0.982\n",
      "Epoch 837/1000,  Loss: 0.1081,  Accuracy: 0.982\n",
      "Epoch 838/1000,  Loss: 0.108,  Accuracy: 0.982\n",
      "Epoch 839/1000,  Loss: 0.108,  Accuracy: 0.982\n",
      "Epoch 840/1000,  Loss: 0.1079,  Accuracy: 0.982\n",
      "Epoch 841/1000,  Loss: 0.1078,  Accuracy: 0.982\n",
      "Epoch 842/1000,  Loss: 0.1078,  Accuracy: 0.982\n",
      "Epoch 843/1000,  Loss: 0.1077,  Accuracy: 0.982\n",
      "Epoch 844/1000,  Loss: 0.1076,  Accuracy: 0.982\n",
      "Epoch 845/1000,  Loss: 0.1076,  Accuracy: 0.982\n",
      "Epoch 846/1000,  Loss: 0.1075,  Accuracy: 0.982\n",
      "Epoch 847/1000,  Loss: 0.1074,  Accuracy: 0.982\n",
      "Epoch 848/1000,  Loss: 0.1074,  Accuracy: 0.982\n",
      "Epoch 849/1000,  Loss: 0.1073,  Accuracy: 0.982\n",
      "Epoch 850/1000,  Loss: 0.1072,  Accuracy: 0.982\n",
      "Epoch 851/1000,  Loss: 0.1072,  Accuracy: 0.982\n",
      "Epoch 852/1000,  Loss: 0.1071,  Accuracy: 0.982\n",
      "Epoch 853/1000,  Loss: 0.1071,  Accuracy: 0.982\n",
      "Epoch 854/1000,  Loss: 0.107,  Accuracy: 0.982\n",
      "Epoch 855/1000,  Loss: 0.1069,  Accuracy: 0.982\n",
      "Epoch 856/1000,  Loss: 0.1069,  Accuracy: 0.982\n",
      "Epoch 857/1000,  Loss: 0.1068,  Accuracy: 0.982\n",
      "Epoch 858/1000,  Loss: 0.1067,  Accuracy: 0.982\n",
      "Epoch 859/1000,  Loss: 0.1067,  Accuracy: 0.982\n",
      "Epoch 860/1000,  Loss: 0.1066,  Accuracy: 0.982\n",
      "Epoch 861/1000,  Loss: 0.1065,  Accuracy: 0.982\n",
      "Epoch 862/1000,  Loss: 0.1065,  Accuracy: 0.982\n",
      "Epoch 863/1000,  Loss: 0.1064,  Accuracy: 0.982\n",
      "Epoch 864/1000,  Loss: 0.1064,  Accuracy: 0.982\n",
      "Epoch 865/1000,  Loss: 0.1063,  Accuracy: 0.982\n",
      "Epoch 866/1000,  Loss: 0.1062,  Accuracy: 0.982\n",
      "Epoch 867/1000,  Loss: 0.1062,  Accuracy: 0.982\n",
      "Epoch 868/1000,  Loss: 0.1061,  Accuracy: 0.982\n",
      "Epoch 869/1000,  Loss: 0.106,  Accuracy: 0.982\n",
      "Epoch 870/1000,  Loss: 0.106,  Accuracy: 0.982\n",
      "Epoch 871/1000,  Loss: 0.1059,  Accuracy: 0.982\n",
      "Epoch 872/1000,  Loss: 0.1059,  Accuracy: 0.982\n",
      "Epoch 873/1000,  Loss: 0.1058,  Accuracy: 0.982\n",
      "Epoch 874/1000,  Loss: 0.1057,  Accuracy: 0.982\n",
      "Epoch 875/1000,  Loss: 0.1057,  Accuracy: 0.982\n",
      "Epoch 876/1000,  Loss: 0.1056,  Accuracy: 0.982\n",
      "Epoch 877/1000,  Loss: 0.1055,  Accuracy: 0.982\n",
      "Epoch 878/1000,  Loss: 0.1055,  Accuracy: 0.982\n",
      "Epoch 879/1000,  Loss: 0.1054,  Accuracy: 0.982\n",
      "Epoch 880/1000,  Loss: 0.1054,  Accuracy: 0.982\n",
      "Epoch 881/1000,  Loss: 0.1053,  Accuracy: 0.982\n",
      "Epoch 882/1000,  Loss: 0.1052,  Accuracy: 0.982\n",
      "Epoch 883/1000,  Loss: 0.1052,  Accuracy: 0.982\n",
      "Epoch 884/1000,  Loss: 0.1051,  Accuracy: 0.982\n",
      "Epoch 885/1000,  Loss: 0.1051,  Accuracy: 0.982\n",
      "Epoch 886/1000,  Loss: 0.105,  Accuracy: 0.982\n",
      "Epoch 887/1000,  Loss: 0.1049,  Accuracy: 0.982\n",
      "Epoch 888/1000,  Loss: 0.1049,  Accuracy: 0.982\n",
      "Epoch 889/1000,  Loss: 0.1048,  Accuracy: 0.982\n",
      "Epoch 890/1000,  Loss: 0.1048,  Accuracy: 0.982\n",
      "Epoch 891/1000,  Loss: 0.1047,  Accuracy: 0.982\n",
      "Epoch 892/1000,  Loss: 0.1046,  Accuracy: 0.982\n",
      "Epoch 893/1000,  Loss: 0.1046,  Accuracy: 0.982\n",
      "Epoch 894/1000,  Loss: 0.1045,  Accuracy: 0.982\n",
      "Epoch 895/1000,  Loss: 0.1045,  Accuracy: 0.982\n",
      "Epoch 896/1000,  Loss: 0.1044,  Accuracy: 0.982\n",
      "Epoch 897/1000,  Loss: 0.1043,  Accuracy: 0.982\n",
      "Epoch 898/1000,  Loss: 0.1043,  Accuracy: 0.982\n",
      "Epoch 899/1000,  Loss: 0.1042,  Accuracy: 0.982\n",
      "Epoch 900/1000,  Loss: 0.1042,  Accuracy: 0.982\n",
      "Epoch 901/1000,  Loss: 0.1041,  Accuracy: 0.982\n",
      "Epoch 902/1000,  Loss: 0.104,  Accuracy: 0.982\n",
      "Epoch 903/1000,  Loss: 0.104,  Accuracy: 0.982\n",
      "Epoch 904/1000,  Loss: 0.1039,  Accuracy: 0.982\n",
      "Epoch 905/1000,  Loss: 0.1039,  Accuracy: 0.982\n",
      "Epoch 906/1000,  Loss: 0.1038,  Accuracy: 0.982\n",
      "Epoch 907/1000,  Loss: 0.1037,  Accuracy: 0.982\n",
      "Epoch 908/1000,  Loss: 0.1037,  Accuracy: 0.982\n",
      "Epoch 909/1000,  Loss: 0.1036,  Accuracy: 0.982\n",
      "Epoch 910/1000,  Loss: 0.1036,  Accuracy: 0.982\n",
      "Epoch 911/1000,  Loss: 0.1035,  Accuracy: 0.982\n",
      "Epoch 912/1000,  Loss: 0.1035,  Accuracy: 0.982\n",
      "Epoch 913/1000,  Loss: 0.1034,  Accuracy: 0.982\n",
      "Epoch 914/1000,  Loss: 0.1033,  Accuracy: 0.982\n",
      "Epoch 915/1000,  Loss: 0.1033,  Accuracy: 0.982\n",
      "Epoch 916/1000,  Loss: 0.1032,  Accuracy: 0.982\n",
      "Epoch 917/1000,  Loss: 0.1032,  Accuracy: 0.982\n",
      "Epoch 918/1000,  Loss: 0.1031,  Accuracy: 0.982\n",
      "Epoch 919/1000,  Loss: 0.1031,  Accuracy: 0.982\n",
      "Epoch 920/1000,  Loss: 0.103,  Accuracy: 0.982\n",
      "Epoch 921/1000,  Loss: 0.1029,  Accuracy: 0.982\n",
      "Epoch 922/1000,  Loss: 0.1029,  Accuracy: 0.982\n",
      "Epoch 923/1000,  Loss: 0.1028,  Accuracy: 0.982\n",
      "Epoch 924/1000,  Loss: 0.1028,  Accuracy: 0.982\n",
      "Epoch 925/1000,  Loss: 0.1027,  Accuracy: 0.982\n",
      "Epoch 926/1000,  Loss: 0.1027,  Accuracy: 0.982\n",
      "Epoch 927/1000,  Loss: 0.1026,  Accuracy: 0.982\n",
      "Epoch 928/1000,  Loss: 0.1026,  Accuracy: 0.982\n",
      "Epoch 929/1000,  Loss: 0.1025,  Accuracy: 0.982\n",
      "Epoch 930/1000,  Loss: 0.1024,  Accuracy: 0.982\n",
      "Epoch 931/1000,  Loss: 0.1024,  Accuracy: 0.982\n",
      "Epoch 932/1000,  Loss: 0.1023,  Accuracy: 0.982\n",
      "Epoch 933/1000,  Loss: 0.1023,  Accuracy: 0.982\n",
      "Epoch 934/1000,  Loss: 0.1022,  Accuracy: 0.982\n",
      "Epoch 935/1000,  Loss: 0.1022,  Accuracy: 0.982\n",
      "Epoch 936/1000,  Loss: 0.1021,  Accuracy: 0.982\n",
      "Epoch 937/1000,  Loss: 0.1021,  Accuracy: 0.982\n",
      "Epoch 938/1000,  Loss: 0.102,  Accuracy: 0.982\n",
      "Epoch 939/1000,  Loss: 0.1019,  Accuracy: 0.982\n",
      "Epoch 940/1000,  Loss: 0.1019,  Accuracy: 0.982\n",
      "Epoch 941/1000,  Loss: 0.1018,  Accuracy: 0.982\n",
      "Epoch 942/1000,  Loss: 0.1018,  Accuracy: 0.982\n",
      "Epoch 943/1000,  Loss: 0.1017,  Accuracy: 0.982\n",
      "Epoch 944/1000,  Loss: 0.1017,  Accuracy: 0.982\n",
      "Epoch 945/1000,  Loss: 0.1016,  Accuracy: 0.982\n",
      "Epoch 946/1000,  Loss: 0.1016,  Accuracy: 0.982\n",
      "Epoch 947/1000,  Loss: 0.1015,  Accuracy: 0.982\n",
      "Epoch 948/1000,  Loss: 0.1015,  Accuracy: 0.982\n",
      "Epoch 949/1000,  Loss: 0.1014,  Accuracy: 0.982\n",
      "Epoch 950/1000,  Loss: 0.1013,  Accuracy: 0.982\n",
      "Epoch 951/1000,  Loss: 0.1013,  Accuracy: 0.982\n",
      "Epoch 952/1000,  Loss: 0.1012,  Accuracy: 0.982\n",
      "Epoch 953/1000,  Loss: 0.1012,  Accuracy: 0.982\n",
      "Epoch 954/1000,  Loss: 0.1011,  Accuracy: 0.982\n",
      "Epoch 955/1000,  Loss: 0.1011,  Accuracy: 0.982\n",
      "Epoch 956/1000,  Loss: 0.101,  Accuracy: 0.982\n",
      "Epoch 957/1000,  Loss: 0.101,  Accuracy: 0.982\n",
      "Epoch 958/1000,  Loss: 0.1009,  Accuracy: 0.982\n",
      "Epoch 959/1000,  Loss: 0.1009,  Accuracy: 0.982\n",
      "Epoch 960/1000,  Loss: 0.1008,  Accuracy: 0.982\n",
      "Epoch 961/1000,  Loss: 0.1008,  Accuracy: 0.982\n",
      "Epoch 962/1000,  Loss: 0.1007,  Accuracy: 0.982\n",
      "Epoch 963/1000,  Loss: 0.1006,  Accuracy: 0.982\n",
      "Epoch 964/1000,  Loss: 0.1006,  Accuracy: 0.982\n",
      "Epoch 965/1000,  Loss: 0.1005,  Accuracy: 0.982\n",
      "Epoch 966/1000,  Loss: 0.1005,  Accuracy: 0.982\n",
      "Epoch 967/1000,  Loss: 0.1004,  Accuracy: 0.982\n",
      "Epoch 968/1000,  Loss: 0.1004,  Accuracy: 0.982\n",
      "Epoch 969/1000,  Loss: 0.1003,  Accuracy: 0.982\n",
      "Epoch 970/1000,  Loss: 0.1003,  Accuracy: 0.982\n",
      "Epoch 971/1000,  Loss: 0.1002,  Accuracy: 0.982\n",
      "Epoch 972/1000,  Loss: 0.1002,  Accuracy: 0.982\n",
      "Epoch 973/1000,  Loss: 0.1001,  Accuracy: 0.982\n",
      "Epoch 974/1000,  Loss: 0.1001,  Accuracy: 0.982\n",
      "Epoch 975/1000,  Loss: 0.1,  Accuracy: 0.982\n",
      "Epoch 976/1000,  Loss: 0.1,  Accuracy: 0.982\n",
      "Epoch 977/1000,  Loss: 0.0999,  Accuracy: 0.982\n",
      "Epoch 978/1000,  Loss: 0.0999,  Accuracy: 0.982\n",
      "Epoch 979/1000,  Loss: 0.0998,  Accuracy: 0.982\n",
      "Epoch 980/1000,  Loss: 0.0998,  Accuracy: 0.982\n",
      "Epoch 981/1000,  Loss: 0.0997,  Accuracy: 0.982\n",
      "Epoch 982/1000,  Loss: 0.0997,  Accuracy: 0.982\n",
      "Epoch 983/1000,  Loss: 0.0996,  Accuracy: 0.982\n",
      "Epoch 984/1000,  Loss: 0.0996,  Accuracy: 0.982\n",
      "Epoch 985/1000,  Loss: 0.0995,  Accuracy: 0.982\n",
      "Epoch 986/1000,  Loss: 0.0995,  Accuracy: 0.982\n",
      "Epoch 987/1000,  Loss: 0.0994,  Accuracy: 0.982\n",
      "Epoch 988/1000,  Loss: 0.0994,  Accuracy: 0.982\n",
      "Epoch 989/1000,  Loss: 0.0993,  Accuracy: 0.982\n",
      "Epoch 990/1000,  Loss: 0.0993,  Accuracy: 0.982\n",
      "Epoch 991/1000,  Loss: 0.0992,  Accuracy: 0.982\n",
      "Epoch 992/1000,  Loss: 0.0992,  Accuracy: 0.982\n",
      "Epoch 993/1000,  Loss: 0.0991,  Accuracy: 0.982\n",
      "Epoch 994/1000,  Loss: 0.0991,  Accuracy: 0.982\n",
      "Epoch 995/1000,  Loss: 0.099,  Accuracy: 0.982\n",
      "Epoch 996/1000,  Loss: 0.099,  Accuracy: 0.982\n",
      "Epoch 997/1000,  Loss: 0.0989,  Accuracy: 0.982\n",
      "Epoch 998/1000,  Loss: 0.0989,  Accuracy: 0.982\n",
      "Epoch 999/1000,  Loss: 0.0988,  Accuracy: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 1000\n",
    "loss_all = []\n",
    "\n",
    "def accuracy(P, Y):\n",
    "    try:\n",
    "        Y = Y.detach().numpy()\n",
    "        P = P.detach().numpy()\n",
    "    except:\n",
    "        Y = Y.numpy()\n",
    "        P = P.numpy() \n",
    "    P = P > 0.5\n",
    "    return round(np.mean(Y == P), 3)\n",
    "\n",
    "for epoch in tqdm(range(n_epoches)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    Ptrain = model(Xtrain)\n",
    "    loss = criterion(Ptrain, Ytrain)\n",
    "    acc = accuracy(Ptrain, Ytrain)\n",
    "\n",
    "    loss_all.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epoches},  Loss: {round(loss.item(), 4)},  Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "with torch.no_grad():\n",
    "    Ptest = model(Xtest)\n",
    "    Ptest = Ptest > 0.5\n",
    "    acc = accuracy(Ptest, Ytest)\n",
    "    print(f\"test Accuracy: {round(acc, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4b521e29a846470c96e928a1c4aafac58a12234cdaa98f9ca60bc431873fee6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
